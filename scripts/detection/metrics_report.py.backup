"""YOLO Metrics Report

Runs validation for a trained YOLO model and prints:
- Overall Precision, Recall, F1
- mAP50, mAP50-95
- Per-class Precision, Recall, F1, mAP50

Usage:
  python scripts/detection/metrics_report.py
  python scripts/detection/metrics_report.py --weights runs/detect/.../weights/best.pt

Notes:
- "Accuracy" is not a standard detection metric; use Precision/Recall/F1 and mAP.
"""

from __future__ import annotations

import argparse
from pathlib import Path
from typing import Any


def _calc_iou(a: tuple[float, float, float, float], b: tuple[float, float, float, float]) -> float:
    ax1, ay1, ax2, ay2 = a
    bx1, by1, bx2, by2 = b
    ix1 = max(ax1, bx1)
    iy1 = max(ay1, by1)
    ix2 = min(ax2, bx2)
    iy2 = min(ay2, by2)
    if ix2 <= ix1 or iy2 <= iy1:
        return 0.0
    inter = (ix2 - ix1) * (iy2 - iy1)
    a_area = max(0.0, ax2 - ax1) * max(0.0, ay2 - ay1)
    b_area = max(0.0, bx2 - bx1) * max(0.0, by2 - by1)
    union = a_area + b_area - inter
    return (inter / union) if union > 0 else 0.0


def _parse_dataset_yaml(yaml_path: Path) -> tuple[Path, str]:
    """Return (dataset_root, val_images_relpath). Minimal parser to avoid extra deps."""
    if not yaml_path.exists():
        raise FileNotFoundError(f"Dataset YAML not found: {yaml_path}")

    dataset_root: Path | None = None
    val_rel: str | None = None
    for raw in yaml_path.read_text(encoding="utf-8", errors="ignore").splitlines():
        line = raw.strip()
        if not line or line.startswith("#"):
            continue
        if line.startswith("path:"):
            value = line.split(":", 1)[1]
            value = value.split("#", 1)[0].strip().strip('"').strip("'")
            dataset_root = Path(value)
        elif line.startswith("val:"):
            value = line.split(":", 1)[1]
            value = value.split("#", 1)[0].strip().strip('"').strip("'")
            val_rel = value

    if dataset_root is None or val_rel is None:
        raise ValueError(f"Could not parse 'path' and 'val' from {yaml_path}")

    return dataset_root, val_rel


def _list_images(folder: Path) -> list[Path]:
    if not folder.exists():
        return []
    exts = ("*.png", "*.jpg", "*.jpeg")
    out: list[Path] = []
    for e in exts:
        out.extend(folder.glob(e))
    return sorted(out)


def _read_yolo_labels(label_path: Path, img_w: int, img_h: int) -> list[tuple[float, float, float, float]]:
    """Return list of GT boxes in xyxy pixels, ignoring class id."""
    if not label_path.exists():
        return []
    boxes: list[tuple[float, float, float, float]] = []
    for raw in label_path.read_text(encoding="utf-8", errors="ignore").splitlines():
        raw = raw.strip()
        if not raw:
            continue
        parts = raw.split()
        if len(parts) < 5:
            continue
        try:
            x_c, y_c, w, h = map(float, parts[1:5])
        except ValueError:
            continue

        x1 = (x_c - w / 2.0) * img_w
        y1 = (y_c - h / 2.0) * img_h
        x2 = (x_c + w / 2.0) * img_w
        y2 = (y_c + h / 2.0) * img_h

        # Clip
        x1 = max(0.0, min(float(img_w), x1))
        x2 = max(0.0, min(float(img_w), x2))
        y1 = max(0.0, min(float(img_h), y1))
        y2 = max(0.0, min(float(img_h), y2))
        if x2 <= x1 or y2 <= y1:
            continue
        boxes.append((x1, y1, x2, y2))
    return boxes


def compute_class_agnostic_prf1(
    *,
    model,
    data_yaml: Path,
    imgsz: int,
    conf: float,
    iou_thresh: float,
    device: int | str | None = None,
) -> tuple[float, float, float, int, int, int]:
    """Compute class-agnostic precision/recall/F1 at a fixed conf and IoU threshold."""
    import cv2

    dataset_root, val_rel = _parse_dataset_yaml(data_yaml)
    val_images_dir = (dataset_root / val_rel).resolve()
    split_name = Path(val_rel).parts[-1]
    val_labels_dir = (dataset_root / "labels" / split_name).resolve()

    images = _list_images(val_images_dir)
    if not images:
        raise FileNotFoundError(f"No validation images found in: {val_images_dir}")

    tp = fp = fn = 0

    for img_path in images:
        img = cv2.imread(str(img_path))
        if img is None:
            continue
        img_h, img_w = img.shape[:2]

        gt_path = val_labels_dir / f"{img_path.stem}.txt"
        gt_boxes = _read_yolo_labels(gt_path, img_w, img_h)
        gt_matched = [False] * len(gt_boxes)

        preds = model.predict(
            source=img,
            imgsz=imgsz,
            conf=conf,
            verbose=False,
            device=device,
        )
        if not preds:
            fn += len(gt_boxes)
            continue

        pred_boxes_xyxy: list[tuple[float, float, float, float]] = []
        boxes = preds[0].boxes
        if boxes is not None and len(boxes) > 0:
            for b in boxes:
                x1, y1, x2, y2 = b.xyxy[0].tolist()
                pred_boxes_xyxy.append((float(x1), float(y1), float(x2), float(y2)))

        # Greedy match predictions -> GT by best IoU
        for pb in pred_boxes_xyxy:
            best_iou = 0.0
            best_j = -1
            for j, gb in enumerate(gt_boxes):
                if gt_matched[j]:
                    continue
                iou = _calc_iou(pb, gb)
                if iou > best_iou:
                    best_iou = iou
                    best_j = j
            if best_iou >= iou_thresh and best_j >= 0:
                tp += 1
                gt_matched[best_j] = True
            else:
                fp += 1

        fn += sum(1 for m in gt_matched if not m)

    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    f1 = _safe_f1(precision, recall)
    return precision, recall, f1, tp, fp, fn


def _safe_f1(precision: float, recall: float) -> float:
    denom = precision + recall
    return (2.0 * precision * recall / denom) if denom > 0 else 0.0


def _find_default_weights() -> Path:
    # Prefer the standardized best model location, then latest training run
    standardized = Path("models/best_trained_model.pt")
    if standardized.exists():
        return standardized
    
    candidates = list(Path("runs/detect").glob("**/weights/best.pt"))
    if not candidates:
        raise FileNotFoundError("No best.pt found. Run grid search analysis or check runs/detect/**/weights/best.pt")
    candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return candidates[0]


def _format_float(x: Any) -> float:
    try:
        return float(x)
    except Exception:
        return 0.0


def main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument("--weights", type=str, default=None, help="Path to YOLO weights (best.pt)")
    parser.add_argument("--data", type=str, default="config/train.yaml", help="Dataset YAML")
    parser.add_argument("--imgsz", type=int, default=1024, help="Validation image size")
    parser.add_argument("--conf", type=float, default=0.25, help="Confidence threshold")
    parser.add_argument("--agnostic", action="store_true", help="Also compute class-agnostic (box-only) P/R/F1")
    parser.add_argument("--iou", type=float, default=0.50, help="IoU threshold for class-agnostic matching")
    args = parser.parse_args()

    weights_path = Path(args.weights) if args.weights else _find_default_weights()
    if not weights_path.exists():
        raise FileNotFoundError(f"Weights not found: {weights_path}")

    try:
        from ultralytics import YOLO
    except Exception as e:
        raise RuntimeError("ultralytics is required. Install with: pip install ultralytics") from e

    print(f"Using weights: {weights_path}")

    model = YOLO(str(weights_path))

    # Run validation (fast on small val set)
    metrics = model.val(
        data=args.data,
        imgsz=args.imgsz,
        conf=args.conf,
        plots=False,
        save_json=False,
        verbose=False,
        workers=0,
    )

    # Overall metrics
    # In Ultralytics, metrics.box.p/r are per-class arrays, while mp/mr are the mean precision/recall.
    overall_p = _format_float(getattr(metrics.box, "mp", 0.0))
    overall_r = _format_float(getattr(metrics.box, "mr", 0.0))
    overall_map50 = _format_float(getattr(metrics.box, "map50", 0.0))
    overall_map = _format_float(getattr(metrics.box, "map", 0.0))
    overall_f1 = _safe_f1(overall_p, overall_r)

    print("\nOverall")
    print(f"  Precision:   {overall_p:.4f}")
    print(f"  Recall:      {overall_r:.4f}")
    print(f"  F1:          {overall_f1:.4f}")
    print(f"  mAP50:       {overall_map50:.4f}")
    print(f"  mAP50-95:    {overall_map:.4f}")

    # Per-class metrics
    names: dict[int, str] = getattr(model, "names", {}) or {}

    # Ultralytics exposes per-class arrays on metrics.box
    per_class_p = getattr(metrics.box, "p", None)
    per_class_r = getattr(metrics.box, "r", None)
    # Per-class mAP50 is available as ap50 (average precision at IoU=0.50) per class.
    per_class_map50 = getattr(metrics.box, "ap50", None)

    # Depending on ultralytics version, per-class arrays might be under different fields.
    # If we detect scalars, try the numpy arrays from box.
    import numpy as np

    def _to_1d_array(x: Any) -> np.ndarray:
        if x is None:
            return np.array([])
        if isinstance(x, (list, tuple)):
            return np.array(x, dtype=float)
        if hasattr(x, "shape"):
            arr = np.asarray(x, dtype=float)
            return arr.reshape(-1)
        # Scalar
        return np.array([])

    p_arr = _to_1d_array(per_class_p)
    r_arr = _to_1d_array(per_class_r)
    map50_arr = _to_1d_array(per_class_map50)

    # If arrays are empty, try metrics.box.class_result (older variants)
    if p_arr.size == 0 or r_arr.size == 0:
        class_result = getattr(metrics.box, "class_result", None)
        if class_result is not None:
            # Expect list of dict-like entries
            try:
                p_arr = np.array([_format_float(x.get("p", 0.0)) for x in class_result], dtype=float)
                r_arr = np.array([_format_float(x.get("r", 0.0)) for x in class_result], dtype=float)
                map50_arr = np.array([_format_float(x.get("map50", 0.0)) for x in class_result], dtype=float)
            except Exception:
                p_arr = np.array([])
                r_arr = np.array([])
                map50_arr = np.array([])

    if p_arr.size and r_arr.size:
        n = min(p_arr.size, r_arr.size)
        print("\nPer-class (sorted by F1 desc)")
        rows = []
        for class_id in range(n):
            p = float(p_arr[class_id])
            r = float(r_arr[class_id])
            f1 = _safe_f1(p, r)
            m50 = float(map50_arr[class_id]) if map50_arr.size > class_id else 0.0
            name = names.get(class_id, str(class_id))
            rows.append((f1, class_id, name, p, r, m50))

        rows.sort(key=lambda x: x[0], reverse=True)

        print(f"{'id':>3}  {'class':<14}  {'P':>7}  {'R':>7}  {'F1':>7}  {'mAP50':>7}")
        print("-" * 60)
        for f1, class_id, name, p, r, m50 in rows:
            print(f"{class_id:>3}  {name:<14.14}  {p:7.3f}  {r:7.3f}  {f1:7.3f}  {m50:7.3f}")
    else:
        print("\nPer-class metrics not available in this ultralytics version.")

    if args.agnostic:
        # Try to use GPU if available; Ultralytics accepts device=0 or 'cpu'
        try:
            import torch

            device = 0 if torch.cuda.is_available() else "cpu"
        except Exception:
            device = None

        p, r, f1, tp, fp, fn = compute_class_agnostic_prf1(
            model=model,
            data_yaml=Path(args.data),
            imgsz=args.imgsz,
            conf=args.conf,
            iou_thresh=args.iou,
            device=device,
        )
        print("\nClass-agnostic (box-only; ignores class labels)")
        print(f"  IoU threshold: {args.iou:.2f}")
        print(f"  Conf threshold: {args.conf:.2f}")
        print(f"  TP/FP/FN: {tp}/{fp}/{fn}")
        print(f"  Precision: {p:.4f}")
        print(f"  Recall:    {r:.4f}")
        print(f"  F1:        {f1:.4f}")


if __name__ == "__main__":
    main()
